# FutureMakers2022

Reflections:

7/6: Today, I learned about the basic operations of python as well as basic methods for pandas and numpy. Overall, this was mostly a review, but it helped to warm up my coding skills in order to prepare for what we learn next.

7/7: The most interesting thing from today was working with the GraphViz library, which helped me visualize the decision tree and random forest models on the iris dataset. It was very interesting to see the actual "decisions" the computer made in order to arrive at its final classification. It was also interesting hearing about semisupervised and reinforcement learning.

7/8: Today I learned about the basics of deep learning using Tensorflow. Fortunately, I already have experience using tensorflow, but it was a good review nonetheless. I particularly liked how we compared all of the different kinds of models, and well as different model architectures, in order to better understand it.

7/12: Today I learned more about Tensorflow and worked with the different operations that one can do with tensors. I also explored the mnist dataset, and created a model that could classify the different pieces of items.

7/13: Today I learned about the inner working behind a deep learning algorithm, namely the forward pass and backpropogation functions. The notebook walked through actually coding these functions, and it was very interesting to see a "homemade" MLP. 

7/14: Today I learned about Convolution Neural Networks and their unique ability to extrapolate patterns from visual data. I saw various convolutional layers that could be used, and experimented with different pooling options.

7/18: Today I learned about the different compenents of a CNN such as the convoltion layer, pooling layers, dropout and batch normalization layers. It was interesting to learn what purpose each of these layers serve.

7/19: Today I learned about various loss functions and their different use cases. It was very interesting to actually code some of them and see them in action.

7/20: Today I learned about the different activations functions and their purposes. We started with signmoid and then moved to relu and other variations. Fianlly, we wrote each of the functions and graphed them.

7/21: Today I learned about ethics in AI and the different problems that our society faces. I was shocked to hear some of the stories, especially about the person with cerebral palsy who had her help stripped away. AI is certainly not perfect, but being aware of this problem is crucial to help prevent it.

7/22: Today I created a CNN from scratch using tensorflow for the dog vs cat classification task.

7/25: Today I created the reasons for underfitting and overfitting, and what we can do to prevent them. Sepcifically, we looked at decreasing model complixity with regularization and lower layer numbers, and we graphed their performance over 20 epochs.

7/26: Today I learned about affective computing and explored a model that classiifed audio signals from male and female actors into various emotional categories. 
